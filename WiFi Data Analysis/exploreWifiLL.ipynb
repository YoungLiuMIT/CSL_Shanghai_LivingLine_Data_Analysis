{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import urllib\n",
    "import re\n",
    "import datetime\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 load data(for raw data and clean data respectively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 load the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './2018-05-24_01 2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f0516bd86a62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#load the rae data and turn it into the json format(notes: you should put the data and the ipynb folder in a folder together)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'./2018-05-24_01 2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdataRawJson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: './2018-05-24_01 2'"
     ]
    }
   ],
   "source": [
    "#load the rae data and turn it into the json format(notes: you should put the data and the ipynb folder in a folder together)\n",
    "from io import open\n",
    "filepath='insertYourFilePath'\n",
    "with open (filepath+'./2018-05-24_01 2','r', encoding='utf-8',errors='replace') as myfile:\n",
    "    data = myfile.readlines()\n",
    "    dataRawJson=[json.loads(data[i]) for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 load the clean data into the json format and extract the valid macs in order to compare it with those in the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './pri-2018-05-24_01'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-89ad138443a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'./pri-2018-05-24_01'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#load the clean data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataFormatted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'['\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'}\\s*{'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'},{'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m']'\u001b[0m \u001b[1;31m#methods for formatting the data: search for }{, ignoring whitespace, add a comma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdataCleanJson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataFormatted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#format the clean data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: './pri-2018-05-24_01'"
     ]
    }
   ],
   "source": [
    "with open ('./pri-2018-05-24_01','r',encoding='utf-8',errors='replace') as myfile:\n",
    "    data = myfile.readlines() #load the clean data\n",
    "    \n",
    "dataFormatted = '['+re.sub('}\\s*{','},{',data[0])+']' #methods for formatting the data: search for }{, ignoring whitespace, add a comma \n",
    "dataCleanJson=json.loads(dataFormatted)#format the clean data\n",
    "dataCleanJsonLists=[[rec['data'][i].split(',')for i in range(len(rec['data']))]for rec in dataCleanJson]#split each row with comma\n",
    "validMacs = [[record[i][5] for i in range(len(record))] for record in dataCleanJsonLists]#extract the valid macs in the clean data\n",
    "uniqueValidMacs=set([mac for macList in validMacs for mac in macList])#get the unique valid macs\n",
    "numUniqueValidMacs = len(uniqueValidMacs)#calculate the numbers of the valid macs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 parse the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 select the valid macs and extract the useful features like probe/ts/datetime/rssi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the basic encoding environment for elements in raw data,\n",
    "timeCorrection=8*60*60\n",
    "allTimes=[]\n",
    "individuals={}\n",
    "c=0\n",
    "for record in dataRawJson:\n",
    "    c+=1\n",
    "    #print(c)\n",
    "    wifi=record['wifidata']\n",
    "    apmac=wifi['apmac']\n",
    "    ts=float(wifi['tssend'])+timeCorrection #we should use the time when it send out the data which is more accurate\n",
    "    allTimes.extend([ts])\n",
    "    dateTime=datetime.datetime.utcfromtimestamp(ts/1000).strftime('%Y%m%d %H:%M:%S') #use datetime to transfer into the local time\n",
    "    count=wifi['count']\n",
    "    for obs in wifi['wifitalist']: #define information in wifitalist and\n",
    "        valid=obs['mac'] in uniqueValidMacs\n",
    "        newObs={'probe':apmac,\n",
    "                'ts':ts,\n",
    "                'datetime':dateTime,\n",
    "                'rssi':obs['rssi']} #rename all the features in wifitalist\n",
    "        if obs['mac'] in individuals:\n",
    "            individuals[obs['mac']]['observations'].append(newObs)\n",
    "        else:\n",
    "            individuals[obs['mac']]={'valid':valid,'observations':[newObs]}\n",
    "obsPerPerson = [len(individuals[i]) for i in individuals]\n",
    "#plt.hist(obsPerPerson,bins=100)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 calculate the percentage of the valid macs in all macs of raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the start time and end time of the ts_send\n",
    "minTime=datetime.datetime.utcfromtimestamp(min(allTimes)/1000).strftime('%Y%m%d %H:%M:%S')\n",
    "maxTime=datetime.datetime.utcfromtimestamp(max(allTimes)/1000).strftime('%Y%m%d %H:%M:%S')\n",
    "#calculate the valid macs in the raw data\n",
    "numValidMacsRaw=sum([individuals[ind]['valid'] for ind in individuals]) #number of the valid macs in raw data\n",
    "numValidObs=sum([individuals[ind]['valid']*len(individuals[ind]['observations'])for ind in individuals])\n",
    "numObs=sum([len(individuals[ind]['observations'])for ind in individuals])\n",
    "pcentValid=100*numValidObs/numObs"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
